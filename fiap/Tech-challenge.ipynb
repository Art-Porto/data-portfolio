{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b770593c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.50.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-6.2.1-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (2.3.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (2.3.3)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-extensions<5,>=4.4.0 (from streamlit)\n",
      "  Downloading typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from streamlit) (6.5.2)\n",
      "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema-4.25.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-2.8.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->streamlit)\n",
      "  Downloading certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit)\n",
      "  Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arthur porto\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Downloading streamlit-1.50.0-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 6.0/10.1 MB 33.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 33.8 MB/s  0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 731.2/731.2 kB 34.7 MB/s  0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-6.2.1-py3-none-any.whl (11 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading pillow-11.3.0-cp313-cp313-win_amd64.whl (7.0 MB)\n",
      "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 7.0/7.0 MB 39.0 MB/s  0:00:00\n",
      "Downloading protobuf-6.33.0-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.9/6.9 MB 42.0 MB/s  0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema-4.25.1-py3-none-any.whl (90 kB)\n",
      "Downloading attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Downloading jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)\n",
      "Downloading narwhals-2.8.0-py3-none-any.whl (415 kB)\n",
      "Downloading pyarrow-21.0.0-cp313-cp313-win_amd64.whl (26.1 MB)\n",
      "   ---------------------------------------- 0.0/26.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 8.9/26.1 MB 44.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 17.0/26.1 MB 43.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.0/26.1 MB 43.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.1/26.1 MB 41.2 MB/s  0:00:00\n",
      "Downloading referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Downloading rpds_py-0.27.1-cp313-cp313-win_amd64.whl (232 kB)\n",
      "Installing collected packages: watchdog, urllib3, typing-extensions, toml, tenacity, smmap, rpds-py, pyarrow, protobuf, pillow, narwhals, MarkupSafe, idna, click, charset_normalizer, certifi, cachetools, blinker, attrs, requests, referencing, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\n",
      "   - --------------------------------------  1/29 [urllib3]\n",
      "   ----- ----------------------------------  4/29 [tenacity]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   --------- ------------------------------  7/29 [pyarrow]\n",
      "   ----------- ----------------------------  8/29 [protobuf]\n",
      "   ----------- ----------------------------  8/29 [protobuf]\n",
      "   ------------ ---------------------------  9/29 [pillow]\n",
      "   ------------ ---------------------------  9/29 [pillow]\n",
      "   ------------ ---------------------------  9/29 [pillow]\n",
      "   ------------- -------------------------- 10/29 [narwhals]\n",
      "   ------------- -------------------------- 10/29 [narwhals]\n",
      "   ------------- -------------------------- 10/29 [narwhals]\n",
      "   ------------- -------------------------- 10/29 [narwhals]\n",
      "   ----------------- ---------------------- 13/29 [click]\n",
      "   -------------------- ------------------- 15/29 [certifi]\n",
      "   -------------------------- ------------- 19/29 [requests]\n",
      "   ---------------------------- ----------- 21/29 [jinja2]\n",
      "   ------------------------------ --------- 22/29 [gitdb]\n",
      "   ------------------------------- -------- 23/29 [pydeck]\n",
      "   ---------------------------------- ----- 25/29 [gitpython]\n",
      "   ----------------------------------- ---- 26/29 [jsonschema]\n",
      "   ------------------------------------- -- 27/29 [altair]\n",
      "   ------------------------------------- -- 27/29 [altair]\n",
      "   ------------------------------------- -- 27/29 [altair]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   -------------------------------------- - 28/29 [streamlit]\n",
      "   ---------------------------------------- 29/29 [streamlit]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 altair-5.5.0 attrs-25.4.0 blinker-1.9.0 cachetools-6.2.1 certifi-2025.10.5 charset_normalizer-3.4.4 click-8.3.0 gitdb-4.0.12 gitpython-3.1.45 idna-3.11 jinja2-3.1.6 jsonschema-4.25.1 jsonschema-specifications-2025.9.1 narwhals-2.8.0 pillow-11.3.0 protobuf-6.33.0 pyarrow-21.0.0 pydeck-0.9.1 referencing-0.37.0 requests-2.32.5 rpds-py-0.27.1 smmap-5.0.2 streamlit-1.50.0 tenacity-9.1.2 toml-0.10.2 typing-extensions-4.15.0 urllib3-2.5.0 watchdog-6.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ee08ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-19 09:00:59.422 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-19 09:00:59.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-10-19 09:00:59.423 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import streamlit as st\n",
    "\n",
    "# Subindo e tratando os dados\n",
    "exportacao = pd.read_csv('ExpVinho.csv', sep=';')\n",
    "exportacao_visualizador = pd.DataFrame(exportacao)\n",
    "\n",
    "# excluindo a coluna 'Id', porque não é uma informação útil para a análise\n",
    "exportacao = exportacao.drop('Id', axis=1)\n",
    "\n",
    "# o problema de negócio pede que sejam analisados os últimos 15 anos\n",
    "# como cada coluna representa um valor de quantidade e de valor monetário por ano, será conservado somente as últimas 30 colunas\n",
    "colunas = exportacao.columns[-30:]\n",
    "colunas = colunas.insert(0, 'País')\n",
    "exportacao = exportacao[colunas]\n",
    "\n",
    "# corrigindo a atribuição\n",
    "exportacao.loc[2, 'País'] = 'Alemanha'\n",
    "\n",
    "# retirando do dataframe os países que não compraram vinho com o Brasil\n",
    "exportacao['total'] = exportacao.sum(numeric_only=True, axis=1)\n",
    "paises_comercio_zero = exportacao[exportacao['total'] == 0]\n",
    "exportacao = exportacao.drop(paises_comercio_zero.index, axis=0)\n",
    "exportacao = exportacao.drop('total', axis=1)\n",
    "\n",
    "# exibindo no Streamlit (novo formato)\n",
    "st.dataframe(exportacao, width='stretch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e594c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando os valores das variáveis 'quantidade' e 'valor' que hoje estão representadas no dataframe como ANO e ANO.1 respectivamente\n",
    "quantidadel = []\n",
    "valoruss = []\n",
    "for item in exportacao.columns:\n",
    "    if item == 'País':\n",
    "        quantidadel.append(item)\n",
    "        valoruss.append(item)\n",
    "    elif len(item) == 4:\n",
    "        quantidadel.append(item)\n",
    "    else:\n",
    "        valoruss.append(item)\n",
    "# criando dataframes separados para quantidade e valor\n",
    "quantidade_l = exportacao[quantidadel]\n",
    "quantidade_l = quantidade_l.set_index('País')\n",
    "valor_uss = exportacao[valoruss]\n",
    "valor_uss = valor_uss.set_index('País')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edeb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirando o '.1' do valor da coluna para que futuramente seja possível juntar as tabelas\n",
    "colunas = valor_uss.columns.str[:-2]\n",
    "valor_uss.columns = colunas\n",
    "valor_uss.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff8539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo o melt e criando um dataframe único com informações de quantidade e valor\n",
    "valor_uss2 = valor_uss.reset_index('País')\n",
    "quantidade_l2 = quantidade_l.reset_index('País')\n",
    "\n",
    "quantidade_l2 = quantidade_l2.melt(id_vars=['País'], value_vars=quantidade_l.columns)\n",
    "valor_uss2 = valor_uss2.melt(id_vars=['País'], value_vars=valor_uss.columns)\n",
    "\n",
    "# renomeando as colunas para a correta identificação das variáveis\n",
    "quantidade_l2.columns = ['pais_destino', 'ano', 'quantidade_l']\n",
    "valor_uss2.columns = ['pais_destino', 'ano', 'valor_uss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb1e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo o .join() entre as duas tabelas para tranasformá-la em uma só\n",
    "exportacao_long = quantidade_l2.join(valor_uss2['valor_uss'])\n",
    "exportacao_long.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8ab153",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportacao_long_por_pais = exportacao_long.groupby(by='pais_destino').sum(numeric_only=True)\n",
    "exportacao_long_por_pais = exportacao_long_por_pais.sort_values(by='valor_uss', ascending=False)\n",
    "exportacao_long_por_pais.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportacao_long_por_pais_top10 = exportacao_long_por_pais.head(10)\n",
    "exportacao_long_por_pais_top10 = exportacao_long_por_pais_top10.reset_index('pais_destino')\n",
    "exportacao_long_por_pais_top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b738a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = pd.read_excel('codigo_iso-alpha_top10_paises_importadores_vinho.xlsx')\n",
    "df_aux.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7474dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo o .join() entre as duas tabelas para tranasformá-la em uma só\n",
    "exportacao_long_por_pais_top10 = exportacao_long_por_pais_top10.join(df_aux[['cod_num', 'iso_alpha']])\n",
    "exportacao_long_por_pais_top10.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f71946",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportacao_long_por_pais_top10['pais_origem'] = 'Brasil'\n",
    "exportacao_long_por_pais_top10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exportacao_long_por_pais['dolar_por_litro'] = exportacao_long_por_pais['valor_uss'] / exportacao_long_por_pais['quantidade_l']\n",
    "exportacao_long_por_pais.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d8b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incluindo a coluna total nos dataframe\n",
    "quantidade_l[\"Total_quantidade\"] = quantidade_l.sum(axis=1)\n",
    "valor_uss[\"Total_valor\"] = valor_uss.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d7bcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando dataframe com paises que não compraram vinho do brasil\n",
    "paises_comercio_zero = valor_uss[valor_uss['Total_valor'] == 0]\n",
    "paises_comercio_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96772d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retirando dos dataframe quantidade_l e valor_uss os países que não compraram vinho com o brasil\n",
    "quantidade_l_s = quantidade_l.drop(paises_comercio_zero.index, axis=0)\n",
    "valor_uss_s = valor_uss.drop(paises_comercio_zero.index, axis=0)\n",
    "\n",
    "# ordenando por maior quantidade e maior valor\n",
    "quantidade_l_ordenado_por_total = quantidade_l_s.sort_values(by='Total_quantidade', ascending = False)\n",
    "valor_uss_s_ordenado_por_total = valor_uss_s.sort_values(by='Total_valor', ascending = False)\n",
    "\n",
    "# passo 1: retirando a coluna total dos dataframes\n",
    "quantidade_l_ordenado_por_total = quantidade_l_ordenado_por_total.drop('Total_quantidade', axis=1)\n",
    "valor_uss_s_ordenado_por_total = valor_uss_s_ordenado_por_total.drop('Total_valor', axis=1)\n",
    "\n",
    "# passo 2: criando um dataframe com 10 países que mais compraram vinho do brasil\n",
    "quantidade_l_ordenado_por_total_top10 = quantidade_l_ordenado_por_total.head(10)\n",
    "valor_uss_s_ordenado_por_total_top10 = valor_uss_s_ordenado_por_total.head(10)\n",
    "\n",
    "# passo 3: transpondo os dataframe para que seja possível visualizar a serie temporal\n",
    "quantidade_l_ordenado_por_total_top10 = quantidade_l_ordenado_por_total_top10.T\n",
    "valor_uss_s_ordenado_por_total_top10 = valor_uss_s_ordenado_por_total_top10.T\n",
    "\n",
    "# passo 4: mostrando os dataframes\n",
    "display(quantidade_l_ordenado_por_total_top10.head(2))\n",
    "display(valor_uss_s_ordenado_por_total_top10.head(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
